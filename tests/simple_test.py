#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„åˆ†è¯å™¨æµ‹è¯•è„šæœ¬
"""

import sys
import os
# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../dev/src'))

try:
    print("æ­£åœ¨æµ‹è¯•åˆ†è¯å™¨æ¨¡å—å¯¼å…¥...")
    from text_tokenizers import get_available_tokenizers, get_tokenizer_info
    print("âœ“ åˆ†è¯å™¨æ¨¡å—å¯¼å…¥æˆåŠŸ!")
    
    print("\næ­£åœ¨è·å–å¯ç”¨åˆ†è¯å™¨...")
    available_tokenizers = get_available_tokenizers()
    print(f"å¯ç”¨åˆ†è¯å™¨: {available_tokenizers}")
    
    if available_tokenizers:
        print("\næµ‹è¯•ç¬¬ä¸€ä¸ªå¯ç”¨åˆ†è¯å™¨...")
        tokenizer_name = available_tokenizers[0]
        print(f"æ­£åœ¨æµ‹è¯•: {tokenizer_name}")
        
        # è·å–åˆ†è¯å™¨ä¿¡æ¯
        info = get_tokenizer_info(tokenizer_name)
        print(f"åˆ†è¯å™¨ä¿¡æ¯: {info}")
        
        # æµ‹è¯•ASRMetrics
        print("\næ­£åœ¨æµ‹è¯•ASRMetrics...")
        from asr_metrics_refactored import ASRMetrics
        
        metrics = ASRMetrics(tokenizer_name=tokenizer_name)
        print(f"âœ“ ASRMetricsä½¿ç”¨{tokenizer_name}åˆ›å»ºæˆåŠŸ!")
        
        # ç®€å•æµ‹è¯•
        ref = "ä»Šå¤©å¤©æ°”å¾ˆå¥½"
        hyp = "ä»Šå¤©å¤©æ°”å¾ˆå·"
        cer = metrics.calculate_cer(ref, hyp)
        print(f"æµ‹è¯•CERè®¡ç®—: {cer:.4f}")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åˆ†è¯å™¨æ¶æ„å·¥ä½œæ­£å¸¸ã€‚")
        
    else:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„åˆ†è¯å™¨ã€‚è¯·æ£€æŸ¥ä¾èµ–åº“å®‰è£…ã€‚")

except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
    import traceback
    traceback.print_exc() 